{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we do inference on abdomen CT slices using the cascade of 2 UNETs. First to segment the liver then segment liver lesions.\n",
    "\n",
    "Requirements:\n",
    "- pip packages:\n",
    "  - scipy\n",
    "  - numpy\n",
    "  - matplotlib\n",
    "  - dicom\n",
    "  - natsort\n",
    "- A build of the Caffe branch at : https://github.com/mohamed-ezz/caffe/tree/jonlong\n",
    "  - This branch just merges Jon Long's branch : https://github.com/longjon/caffe/ with the class weighting feature by Olaf Ronnenberg (code at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/).\n",
    "  - Class weighting feature is not needed for inference in this notebook, but we unify the caffe dependency for training and inference tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download model weights and define the paths to the deploy prototxts####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get model weights (step1 and step2 models)\n",
    "!wget --tries=2 -O ../models/cascadedfcn/step1/step1_weights.caffemodel https://www.dropbox.com/s/aoykiiuu669igxa/step1_weights.caffemodel?dl=1\n",
    "!wget --tries=2 -O ../models/cascadedfcn/step2/step2_weights.caffemodel https://www.dropbox.com/s/ql10c37d7ura23l/step2_weights.caffemodel?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP1_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step1/step1_deploy.prototxt\"\n",
    "STEP1_MODEL_WEIGHTS   = \"../models/cascadedfcn/step1/step1_weights.caffemodel\"\n",
    "STEP2_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step2/step2_deploy.prototxt\"\n",
    "STEP2_MODEL_WEIGHTS   = \"../models/cascadedfcn/step2/step2_weights.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "print caffe.__file__\n",
    "# Use CPU for inference\n",
    "caffe.set_mode_cpu()\n",
    "# Use GPU for inference\n",
    "#caffe.set_mode_gpu()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "plt.set_cmap('gray')\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DTYPE = np.float\n",
    "SEG_DTYPE = np.uint8\n",
    "\n",
    "import dicom\n",
    "import natsort\n",
    "import glob, os\n",
    "import re\n",
    "def read_dicom_series(directory, filepattern = \"image_*\"):\n",
    "    \"\"\" Reads a DICOM Series files in the given directory. \n",
    "    Only filesnames matching filepattern will be considered\"\"\"\n",
    "    \n",
    "    if not os.path.exists(directory) or not os.path.isdir(directory):\n",
    "        raise ValueError(\"Given directory does not exist or is a file : \"+str(directory))\n",
    "    print '\\tRead Dicom',directory\n",
    "    lstFilesDCM = natsort.natsorted(glob.glob(os.path.join(directory, filepattern)))\n",
    "    print '\\tLength dicom series',len(lstFilesDCM)\n",
    "    # Get ref file\n",
    "    RefDs = dicom.read_file(lstFilesDCM[0])\n",
    "    # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "    ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM))\n",
    "    # The array is sized based on 'ConstPixelDims'\n",
    "    ArrayDicom = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n",
    "\n",
    "    # loop through all the DICOM files\n",
    "    for filenameDCM in lstFilesDCM:\n",
    "        # read the file\n",
    "        ds = dicom.read_file(filenameDCM)\n",
    "        # store the raw image data\n",
    "        ArrayDicom[:, :, lstFilesDCM.index(filenameDCM)] = ds.pixel_array\n",
    "\n",
    "    return ArrayDicom\n",
    "\n",
    "def read_liver_lesion_masks(masks_dirname):\n",
    "    \"\"\"Since 3DIRCAD provides an individual mask for each tissue type (in DICOM series format),\n",
    "    we merge multiple tissue types into one Tumor mask, and merge this mask with the liver mask\n",
    "    \n",
    "    Args:\n",
    "        masks_dirname : MASKS_DICOM directory containing multiple DICOM series directories, \n",
    "                        one for each labelled mask\n",
    "    Returns:\n",
    "        numpy array with 0's for background pixels, 1's for liver pixels and 2's for tumor pixels\n",
    "    \"\"\"\n",
    "    tumor_volume = None\n",
    "    liver_volume = None\n",
    "    \n",
    "    # For each relevant organ in the current volume\n",
    "    for organ in os.listdir(masks_dirname):\n",
    "        organ_path = os.path.join(masks_dirname,organ)\n",
    "        if not os.path.isdir(organ_path):\n",
    "            continue\n",
    "        \n",
    "        organ = organ.lower()\n",
    "        \n",
    "        if organ.startswith(\"livertumor\") or re.match(\"liver.yst.*\", organ) or organ.startswith(\"stone\") or organ.startswith(\"metastasecto\") :\n",
    "            print 'Organ',masks_dirname,organ\n",
    "            current_tumor = read_dicom_series(organ_path)\n",
    "            current_tumor = np.clip(current_tumor,0,1)\n",
    "            # Merge different tumor masks into a single mask volume\n",
    "            tumor_volume = current_tumor if tumor_volume is None else np.logical_or(tumor_volume,current_tumor)\n",
    "        elif organ == 'liver':\n",
    "            print 'Organ',masks_dirname,organ\n",
    "            liver_volume = read_dicom_series(organ_path)\n",
    "            liver_volume = np.clip(liver_volume, 0, 1)\n",
    "    \n",
    "    # Merge liver and tumor into 1 volume with background=0, liver=1, tumor=2\n",
    "    label_volume = np.zeros(liver_volume.shape)\n",
    "    label_volume[liver_volume==1]=1\n",
    "    label_volume[tumor_volume==1]=2\n",
    "    return label_volume    \n",
    "            \n",
    "def stat(array):\n",
    "    print 'min',np.min(array),'max',np.max(array),'median',np.median(array),'avg',np.mean(array)\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage: \n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "    plt.show()\n",
    "    \n",
    "def to_scale(img, shape=None):\n",
    "\n",
    "    height, width = shape\n",
    "    if img.dtype == SEG_DTYPE:\n",
    "        return scipy.misc.imresize(img,(height,width),interp=\"nearest\").astype(SEG_DTYPE)\n",
    "    elif img.dtype == IMG_DTYPE:\n",
    "        max_ = np.max(img)\n",
    "        factor = 255.0/max_ if max_ != 0 else 1\n",
    "        return (scipy.misc.imresize(img,(height,width),interp=\"nearest\")/factor).astype(IMG_DTYPE)\n",
    "    else:\n",
    "        raise TypeError('Error. To scale the image array, its type must be np.uint8 or np.float64. (' + str(img.dtype) + ')')\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\" Normalize image values to [0,1] \"\"\"\n",
    "    min_, max_ = float(np.min(img)), float(np.max(img))\n",
    "    return (img - min_) / (max_ - min_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Preprocessing functions ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_lbl_slice(lbl_slc):\n",
    "    \"\"\" Preprocess ground truth slice to match output prediction of the network in terms \n",
    "    of size and orientation.\n",
    "    \n",
    "    Args:\n",
    "        lbl_slc: raw label/ground-truth slice\n",
    "    Return:\n",
    "        Preprocessed label slice\"\"\"\n",
    "    lbl_slc = lbl_slc.astype(SEG_DTYPE)\n",
    "    #downscale the label slc for comparison with the prediction\n",
    "    lbl_slc = to_scale(lbl_slc , (388, 388))\n",
    "    return lbl_slc\n",
    "\n",
    "def step1_preprocess_img_slice(img_slc):\n",
    "    \"\"\"\n",
    "    Preprocesses the image 3d volumes by performing the following :\n",
    "    1- Rotate the input volume so the the liver is on the left, spine is at the bottom of the image\n",
    "    2- Set pixels with hounsfield value great than 1200, to zero.\n",
    "    3- Clip all hounsfield values to the range [-100, 400]\n",
    "    4- Normalize values to [0, 1]\n",
    "    5- Rescale img and label slices to 388x388\n",
    "    6- Pad img slices with 92 pixels on all sides (so total shape is 572x572)\n",
    "    \n",
    "    Args:\n",
    "        img_slc: raw image slice\n",
    "    Return:\n",
    "        Preprocessed image slice\n",
    "    \"\"\"      \n",
    "    img_slc   = img_slc.astype(IMG_DTYPE)\n",
    "    img_slc[img_slc>1200] = 0\n",
    "    img_slc   = np.clip(img_slc, -100, 400)    \n",
    "    img_slc   = normalize_image(img_slc)\n",
    "    img_slc   = to_scale(img_slc, (388,388))\n",
    "    img_slc   = np.pad(img_slc,((92,92),(92,92)),mode='reflect')\n",
    "    if False:\n",
    "        img_slc = histeq_processor(img_slc)\n",
    "\n",
    "    return img_slc\n",
    "\n",
    "def step2_preprocess_img_slice(img_p, step1_pred):\n",
    "    \"\"\" Preprocess img slice using the prediction image from step1, by performing\n",
    "    the following :\n",
    "    1- Set non-liver pixels to 0\n",
    "    2- Calculate liver bounding box\n",
    "    3- Crop the liver patch in the input img\n",
    "    4- Resize (usually upscale) the liver patch to the full network input size 388x388\n",
    "    5- Pad image slice with 92 on all sides\n",
    "    \n",
    "    Args:\n",
    "        img_p: Preprocessed image slice\n",
    "        step1_pred: prediction image from step1\n",
    "    Return: \n",
    "        The liver patch and the bounding box coordinate relative to the original img coordinates\"\"\"\n",
    "    \n",
    "    img = img_p[92:-92,92:-92]\n",
    "    pred = step1_pred.astype(SEG_DTYPE)\n",
    "    \n",
    "    # Remove background !\n",
    "    img = np.multiply(img,np.clip(pred,0,1))\n",
    "    # get patch size\n",
    "    col_maxes = np.max(pred, axis=0) # a row\n",
    "    row_maxes = np.max(pred, axis=1)# a column\n",
    "\n",
    "    nonzero_colmaxes = np.nonzero(col_maxes)[0]\n",
    "    nonzero_rowmaxes = np.nonzero(row_maxes)[0]\n",
    "\n",
    "    x1, x2 = nonzero_colmaxes[0], nonzero_colmaxes[-1]\n",
    "    y1, y2 = nonzero_rowmaxes[0], nonzero_rowmaxes[-1]\n",
    "    width = x2-x1\n",
    "    height= y2-y1\n",
    "    MIN_WIDTH = 60\n",
    "    MIN_HEIGHT= 60\n",
    "    x_pad = (MIN_WIDTH - width) / 2 if width < MIN_WIDTH else 0\n",
    "    y_pad = (MIN_HEIGHT - height)/2 if height < MIN_HEIGHT else 0\n",
    "\n",
    "    x1 = max(0, x1-x_pad)\n",
    "    x2 = min(img.shape[1], x2+x_pad)\n",
    "    y1 = max(0, y1-y_pad)\n",
    "    y2 = min(img.shape[0], y2+y_pad)\n",
    "\n",
    "    img = img[y1:y2+1, x1:x2+1]\n",
    "    pred = pred[y1:y2+1, x1:x2+1]\n",
    "\n",
    "    img = to_scale(img, (388,388))\n",
    "    pred = to_scale(pred, (388,388))\n",
    "    # All non-lesion is background\n",
    "    pred[pred==1]=0\n",
    "    #Lesion label becomes 1\n",
    "    pred[pred==2]=1\n",
    "\n",
    "    # Now do padding for UNET, which takes 572x572\n",
    "    #pred=np.pad(pred,((92,92),(92,92)),mode='reflect')\n",
    "    img=np.pad(img,92,mode='reflect')\n",
    "    return img, (x1,x2,y1,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download 3DIRCAD CT volume and merge labeled masks ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download image 17 of 3DIRCAdb1 dataset\n",
    "!wget http://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.17.zip -O 3Dircadb1.17.zip\n",
    "# Unzip into test_image\n",
    "!unzip -o 3Dircadb1.17.zip -d test_image/\n",
    "# Unzip the image CT volume\n",
    "!unzip -o test_image/3Dircadb1.17/PATIENT_DICOM.zip -d test_image/3Dircadb1.17/\n",
    "# Unzip the label masks\n",
    "!unzip -o test_image/3Dircadb1.17/MASKS_DICOM.zip -d test_image/3Dircadb1.17/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=read_dicom_series(\"test_image/3Dircadb1.17/PATIENT_DICOM/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbl=read_liver_lesion_masks(\"test_image/3Dircadb1.17/MASKS_DICOM/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.shape, lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize raw input slices ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in range(50,100,20):\n",
    "    imshow(img[...,s],lbl[...,s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize preprocessed slices ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s in range(50,100,20):\n",
    "    print s\n",
    "    img_p = step1_preprocess_img_slice(img[...,s])\n",
    "    lbl_p = preprocess_lbl_slice(lbl[...,s])\n",
    "    imshow(img_p,lbl_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network prototxt and weights and perform prediction ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare a test slice\n",
    "S = 90\n",
    "img_p = step1_preprocess_img_slice(img[...,S])\n",
    "lbl_p = preprocess_lbl_slice(lbl[...,S])\n",
    "imshow(img_p,lbl_p,title=['Test image','Ground truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load network\n",
    "net1 = caffe.Net(STEP1_DEPLOY_PROTOTXT, STEP1_MODEL_WEIGHTS, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "net1.blobs['data'].data[0,0,...] = img_p\n",
    "pred = net1.forward()['prob'][0,1] > 0.5\n",
    "print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "imshow(img_p, lbl_p, pred>0.5, title=['Slice','Ground truth', 'Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Free up memory of step1 network\n",
    "del net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare liver patch for step2\n",
    "# net1 output is used to determine the predicted liver bounding box\n",
    "img_p2, bbox = step2_preprocess_img_slice(img_p, pred)\n",
    "imshow(img_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load step2 network\n",
    "net2 = caffe.Net(STEP2_DEPLOY_PROTOTXT, STEP2_MODEL_WEIGHTS, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "net2.blobs['data'].data[0,0,...] = img_p2\n",
    "pred2 = net2.forward()['prob'][0,1]\n",
    "print pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize result\n",
    "\n",
    "# extract liver portion as predicted by net1\n",
    "x1,x2,y1,y2 = bbox\n",
    "lbl_p_liver = lbl_p[y1:y2,x1:x2]\n",
    "# Set labels to 0 and 1\n",
    "lbl_p_liver[lbl_p_liver==1]=0\n",
    "lbl_p_liver[lbl_p_liver==2]=1\n",
    "imshow(img_p2[92:-92,92:-92],lbl_p_liver, pred2>0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
